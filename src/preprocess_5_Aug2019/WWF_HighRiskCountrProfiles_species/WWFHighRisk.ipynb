{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textacy\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "from iso3166 import countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermediate file manually edited. Donot lose that !!!!!\n",
    "'WWFHighRisk_intermediate.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All countries\n",
      "['Russia', 'Solomon Islands', 'Bolivia', 'Myanmar', 'Cameroon', 'Malaysia', 'Lao DR', 'Brazil', 'Peru', 'Indonesia', 'China', 'Panama', 'El Salvador', 'DRC', 'Papua New Guinea', 'Gabon', 'Vietnam']\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "def get_df():\n",
    "    file = 'WWF_HighRiskCountryProfiles_Species.xlsx'\n",
    "    df = pd.read_excel(file)\n",
    "    return df\n",
    "df = get_df()\n",
    "\n",
    "countries = list(df['Country of Origin Risk'])\n",
    "\n",
    "def process_country_row(sent):\n",
    "    c_list = sent.replace(\",\" , \" , \")\n",
    "    c_list = c_list.replace('also via', ',')\n",
    "    c_list = c_list.replace('and via', ',')\n",
    "    c_list = c_list.replace('all via', ',')\n",
    "    c_list = c_list.replace(' all', ',')\n",
    "    c_list = c_list.replace(' also', ',')\n",
    "    c_list = c_list.replace(' and', ',')\n",
    "    c_list = c_list.replace(' & ', ',')\n",
    "    c_list = c_list.replace(' also ', ',')\n",
    "    c_list = c_list.replace(' via ', ',')\n",
    "    c_list = c_list.replace('-',' ')\n",
    "    c_list = textacy.preprocess.normalize_whitespace(c_list)\n",
    "    c_list = c_list.split('(Note')[0]\n",
    "    c_list = c_list.split (',')\n",
    "    \n",
    "    res_list=[]\n",
    "    for item in c_list:\n",
    "        item = item.strip()\n",
    "        if len(item) < 20 and len (item) > 0 :\n",
    "            res_list.append(item)\n",
    "            \n",
    "    return res_list\n",
    "\n",
    "# ---------- #\n",
    "# Create a list of all countries , to clean up\n",
    "# ---------- #\n",
    "all_countries = []\n",
    "for c_list in countries:\n",
    "    if type(c_list)!= str:\n",
    "        continue\n",
    "    res_list = process_country_row(c_list)\n",
    "    all_countries.extend(res_list)\n",
    "    \n",
    "all_countries = list(set(all_countries))    \n",
    "print ('All countries')\n",
    "print(all_countries)\n",
    "print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -------------------------------------- #\n",
    "#  Replace the country names!\n",
    "#  Manually curated List \n",
    "#  Using iso31366 package\n",
    "#  from iso3166 import countries\n",
    "#  print(countries.get('us'))\n",
    "#  for c in countries:\n",
    "#        print (c)\n",
    "#  -------------------------------------- #\n",
    "ref_corr_country_names = {\n",
    "    'Bolivia' : 'Bolivia, Plurinational State of',\n",
    "    'Russia' : 'Russian Federation',\n",
    "    'Lao DR' : \"Lao People's Democratic Republic\",\n",
    "    'DRC' : 'Congo, Democratic Republic of the',\n",
    "    'Vietnam' : \"Viet Nam\"\n",
    "}\n",
    "from iso3166 import countries\n",
    "replace_dict = {}\n",
    "\n",
    "for c in all_countries:\n",
    "    if c not in ref_corr_country_names.keys():\n",
    "        res = countries.get(c)\n",
    "    else:\n",
    "        c_name = ref_corr_country_names[c]\n",
    "        res = countries.get(c_name)\n",
    "        \n",
    "    if res is not None:   \n",
    "        replace_dict[c] = res.alpha2\n",
    "    else :\n",
    "        print (\"error\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the country names back in the Data Frame\n",
    "# using replace_dict\n",
    "from iso3166 import countries\n",
    "for i,row in df.iterrows():\n",
    "    sent = row['Country of Origin Risk']\n",
    "    p1 = None \n",
    "    p2 = None\n",
    "    if type(sent) == str :    \n",
    "        # split on via\n",
    "        sent = sent.replace(\",\",\" , \")\n",
    "        parts = sent.split(' via ')\n",
    "        if len(parts) > 1 :\n",
    "            p1 = process_country_row(parts[0])\n",
    "            p2 = process_country_row(parts[1])\n",
    "        else :\n",
    "            p1 = process_country_row(parts[0])\n",
    "        \n",
    "        origins = None\n",
    "        conduit = None\n",
    "        if p1 is not None:\n",
    "            origins = []\n",
    "        \n",
    "        for p in p1 :\n",
    "            if p in ref_corr_country_names.keys():\n",
    "                p = ref_corr_country_names[p]\n",
    "            origins.extend(countries.get(p).alpha2)\n",
    "            \n",
    "        origins = ';'.join(origins)\n",
    "        if p2 is not None:\n",
    "            conduit = []\n",
    "            for p in p2 :\n",
    "                if p in ref_corr_country_names.keys():\n",
    "                    p = ref_corr_country_names[p]\n",
    "                conduit.append(countries.get(p).alpha2)\n",
    "            conduit = ';'.join(conduit)\n",
    "    df.loc[i,'origin'] = origins\n",
    "    df.loc[i,'conduit'] = conduit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out Columns needed\n",
    "df = df[['Taxonomic Genus','Species, if applicable','Common Names','origin','conduit']]\n",
    "df = df.rename(columns ={\n",
    "    'Taxonomic Genus' : 'genus',\n",
    "    'Species, if applicable': 'species',\n",
    "    'Common Names' : 'common_name'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel('WWFHighRisk_intermediate.xlsx')\n",
    "df = pd.read_excel('WWFHighRisk_intermediate_edited.xlsx')\n",
    "                \n",
    "for i,row in df.iterrows():\n",
    "    cn = row['common_name']\n",
    "    if type(cn) != str:\n",
    "        continue\n",
    "    cn = cn.split(',')    \n",
    "    res = []\n",
    "    for c in cn:\n",
    "        c = c.strip()\n",
    "        c = c.lower()\n",
    "        c = textacy.preprocess.normalize_whitespace(c)\n",
    "        res.append(c)\n",
    "    res = ';'.join(res)\n",
    "    df.loc[i,'common_name'] = res\n",
    "df.to_csv('WWF_HighRisk_final.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
