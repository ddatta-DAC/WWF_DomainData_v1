{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Based on :\n",
    "\n",
    "FINAL_LookupTables_US_ITC_HTS_Codes_2015-2017.xlsx\n",
    "https://docs.google.com/spreadsheets/d/1jAx6VSln3-sCxI7R1TDtAVSZjzVsH36MpAq3yKa4e7o/edit#gid=1901895138\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "import re\n",
    "import textacy\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "import math\n",
    "import gen_kw_2\n",
    "import gen_kw_2\n",
    "import filter_hs_codes\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Files\n",
    "1501_hts_delimited.txt\n",
    "hts_2016_basic_delimited.csv\n",
    "hts_2017_preliminary_csv.csv\n",
    "hts_2018_basic_csv.csv\n",
    "'''\n",
    "\n",
    "EXPERIMENT = True\n",
    "\n",
    "def get_file_list_1():\n",
    "    global EXPERIMENT\n",
    "    \n",
    "    if EXPERIMENT == True:\n",
    "        files = {\n",
    "            '1501_hts_delimited.txt': 'hs_codes_file_1_1.csv',\n",
    "            'hts_2016_basic_delimited.csv': 'hs_codes_file_2_1.csv',\n",
    "            'hts_2017_preliminary_csv.csv': 'hs_codes_file_3_1.csv',\n",
    "#             'hts_2018_basic_csv.csv': 'hs_codes_file_4_1.csv'\n",
    "        }\n",
    "    return files\n",
    "\n",
    "    files = {\n",
    "        '1501_hts_delimited.txt': 'hs_codes_file_1.csv',\n",
    "        'hts_2016_basic_delimited.csv': 'hs_codes_file_2.csv',\n",
    "        'hts_2017_preliminary_csv.csv': 'hs_codes_file_3.csv',\n",
    "        'hts_2018_basic_csv.csv': 'hs_codes_file_4.csv',\n",
    "    }\n",
    "    return files\n",
    "\n",
    "def get_file_list_2():\n",
    "    global EXPERIMENT\n",
    "    files = [\n",
    "        'hs_codes_file_1.csv',\n",
    "        'hs_codes_file_2.csv',\n",
    "        'hs_codes_file_3.csv',\n",
    "        'hs_codes_file_4.csv'\n",
    "    ]\n",
    "    \n",
    "    if EXPERIMENT == True:\n",
    "        files = [\n",
    "            'hs_codes_file_1_1.csv',\n",
    "            'hs_codes_file_2_1.csv',\n",
    "            'hs_codes_file_3_1.csv'\n",
    "#             'hs_codes_file_4_1.csv'\n",
    "        ]\n",
    "    return files\n",
    "    return files\n",
    "\n",
    "# ---------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Indent', 'Description', 'hs_code'], dtype='object')\n",
      "-----------------\n",
      "Index(['hs_code', 'Indent', 'Description'], dtype='object')\n",
      "-----------------\n",
      "Index(['hs_code', 'Indent', 'Description'], dtype='object')\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "def process_chg_file(input_file, op_file):\n",
    "    parts = input_file.split('.')\n",
    "    file_ext = parts[1]\n",
    "\n",
    "    if file_ext == 'txt':\n",
    "        df = pd.read_csv(input_file, sep='|', encoding=\"ISO-8859-1\")\n",
    "    else:\n",
    "        df = pd.read_csv(input_file, encoding=\"ISO-8859-1\")\n",
    "\n",
    "    def clean_description(row):\n",
    "        if row is None or row['Description'] is None:\n",
    "            return None\n",
    "        text = str(row['Description'])\n",
    "        if len(text) == 0:\n",
    "            return None\n",
    "#         pattern = re.compile(r'<[^>]+>')\n",
    "#         text = pattern.sub('', text)\n",
    "        strip_chars = ['\\t', ' ', '\\t\\n', ':', ',', ';']\n",
    "        for s in strip_chars:\n",
    "            text = text.strip(s)\n",
    "        text = text.replace(',', ' && ')\n",
    "        text = text.replace(' and ', ' && ')\n",
    "        return text\n",
    "\n",
    "    op_path = op_file\n",
    "    df['Description'] = df.apply(clean_description, 1)\n",
    "    delete_cols = [\n",
    "        'Unit of Quantity',\n",
    "        'General Rate of Duty',\n",
    "        'Special Rate of Duty',\n",
    "        'Column 2 Rate of Duty',\n",
    "        'Col. 1 Rate',\n",
    "        'Special Rate',\n",
    "        'Col. 2 Rate',\n",
    "        'Footnote / Comment',\n",
    "        'Unnamed: 2'\n",
    "    ]\n",
    "\n",
    "    for d in delete_cols:\n",
    "        try:\n",
    "            del df[d]\n",
    "        except:\n",
    "            pass\n",
    "    # in case of 'HTS No.', 'Stat Suffix'  - combine them into 'hs_code'\n",
    "    # also rename Level as Indent\n",
    "\n",
    "    try:\n",
    "        df = df.rename(columns={'Level': 'Indent'})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    def combine_hscode(row):\n",
    "        h1 = row['HTS No.']\n",
    "        h2 = row['Stat Suffix']\n",
    "        if math.isnan(h2) == False and (int(h2)) > 0:\n",
    "            res = h1 + '.' + str(int(h2))\n",
    "        else:\n",
    "            res = h1\n",
    "        return res\n",
    "\n",
    "    df_col_names = list(df.columns)\n",
    "\n",
    "    if ('HTS No.' in df_col_names) and ('Stat Suffix' in df_col_names):\n",
    "        df['hs_code'] = df.apply(combine_hscode, axis=1)\n",
    "        del df['HTS No.']\n",
    "        del df['Stat Suffix']\n",
    "    else:\n",
    "        try:\n",
    "            df = df.rename(columns={'HTS Number': 'hs_code'})\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print(df.columns)\n",
    "    df = filter_hs_codes.filter_df(df,level =1 )\n",
    "    df.to_csv(op_path)\n",
    "    print('-----------------')\n",
    "    return\n",
    "\n",
    "# ----------------------------------- #\n",
    "\n",
    "# Clean and parse from txt/csv to csv. Place files in csv with new names\n",
    "\n",
    "def main_1():\n",
    "    files = get_file_list_1()\n",
    "    for inp, op in files.items():\n",
    "        process_chg_file(inp, op)\n",
    "\n",
    "# ----------------------------------- #\n",
    "\n",
    "main_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract scientific names\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sc_names(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df['sc_names'] = None\n",
    "    for i,row in df.iterrows():\n",
    "        desc_text = row['Description']\n",
    "        if desc_text is None or type(desc_text) != str:\n",
    "            continue\n",
    "        res_list = [] \n",
    "        patterns = [\n",
    "            '\\<\\S+\\>[A-Z][a-z]+\\s[a-z]*\\<\\S+\\>',\n",
    "            '\\<\\S+\\>[A-Z][a-z]+\\s*\\<\\S+\\> [a-z]+\\.',\n",
    "            '\\<\\S+\\>[A-Z][a-z]+\\<\\S+\\> \\<\\S+\\>[a-z]+\\<\\S+\\>'\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns :\n",
    "            search_res = re.findall(pattern,desc_text)\n",
    "            if len(search_res)> 0 :\n",
    "#                 print (' -->' , desc_text)\n",
    "#                 print (search_res)\n",
    "                for grp in range(len(search_res)) :\n",
    "                    _res = search_res[grp]\n",
    "                    _res = ''.join(_res)\n",
    "                    _pattern = re.compile(r'<[^>]+>')\n",
    "                    text = _pattern.sub('', _res)\n",
    "                    text = text.strip()\n",
    "                    res_list.append(text)\n",
    "               \n",
    "        if len(res_list)>0 :\n",
    "            res = ';'.join(res_list)\n",
    "            df.loc[i,'sc_names'] = res\n",
    "        pattern = re.compile(r'<[^>]+>')\n",
    "        text = pattern.sub('', desc_text)   \n",
    "        df.loc[i,'Description'] = text\n",
    "        \n",
    "    df.to_csv(file)\n",
    "    return\n",
    "            \n",
    "def main_2():\n",
    "    files = get_file_list_2()\n",
    "    for inp in files :\n",
    "        get_sc_names(inp)\n",
    "        \n",
    "# ----------------------------------- #  \n",
    "\n",
    "\n",
    "main_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_sc_names(file):\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    def gather_sc_names(df, idx):\n",
    "        cur_row = df.loc[idx]\n",
    "        cur_indent = cur_row['Indent']\n",
    "        indent_attr = 'Indent'\n",
    "        min_idx = 0\n",
    "        res =  cur_row['sc_names']\n",
    "        if type(res)== str :\n",
    "            res = res.split(';')\n",
    "        else:\n",
    "            res = []\n",
    "        cur_idx = idx\n",
    "        \n",
    "        if cur_indent == 0:\n",
    "            return  cur_row['sc_names']\n",
    "        else:\n",
    "            # go up and fetch\n",
    "            cur_idx = idx - 1\n",
    "            \n",
    "            while cur_idx >= min_idx:\n",
    "                r = df.loc[cur_idx]\n",
    "                if r[indent_attr] == cur_indent - 1:\n",
    "                    scn = r['sc_names']\n",
    "                    if type(scn) == str :\n",
    "                        scn = scn.split(';')\n",
    "                        res.extend(scn)\n",
    "                        res = list(set(res))\n",
    "                    break\n",
    "                cur_idx -= 1\n",
    "        if isinstance(res, collections.Iterable) :\n",
    "            tmp = []\n",
    "            for r in res:\n",
    "                if r != '':\n",
    "                    tmp.append(r)\n",
    "            res = ';'.join(tmp)\n",
    "        return res\n",
    "\n",
    "        \n",
    "    for i,row in df.iterrows():\n",
    "        sc_names = gather_sc_names(df, i)\n",
    "        df.at[i, 'sc_names'] = sc_names\n",
    "    df.to_csv(file)\n",
    "        \n",
    "\n",
    "def main_5():\n",
    "    files = get_file_list_2()\n",
    "    for inp in files :\n",
    "        collate_sc_names(inp)\n",
    "\n",
    "main_5()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out the complete descriptions\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_3_aux hs_codes_file_1_1.csv\n",
      "-----------------\n",
      "main_3_aux hs_codes_file_2_1.csv\n",
      "-----------------\n",
      "main_3_aux hs_codes_file_3_1.csv\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "def main_3_aux(file):\n",
    "\n",
    "    def gen_aux_desc(df, idx):\n",
    "        min_idx = 0\n",
    "        neg_keyword = 'Other'\n",
    "        res = None\n",
    "        cur_row = df.loc[idx]\n",
    "        indent_attr = 'Indent'\n",
    "        try:\n",
    "            cur_indent = cur_row['Indent']\n",
    "        except:\n",
    "            cur_indent = cur_row['Level']\n",
    "            indent_attr = 'Level'\n",
    "\n",
    "        cur_desc = cur_row['Description']\n",
    "        is_neg_keyword = False\n",
    "\n",
    "        if type(cur_desc) != str:\n",
    "            cur_desc = ''\n",
    "\n",
    "        if cur_desc == neg_keyword:\n",
    "            is_neg_keyword = True\n",
    "\n",
    "        def format_desc(s):\n",
    "            return '[ ' + s + ' ]'\n",
    "\n",
    "        if cur_indent == 0:\n",
    "            res = format_desc(cur_desc)\n",
    "        else:\n",
    "            # go up and fetch\n",
    "            cur_idx = idx - 1\n",
    "            if is_neg_keyword:\n",
    "                res_parts = []\n",
    "                while cur_idx >= min_idx:\n",
    "                    r = df.loc[cur_idx]\n",
    "                    # Find entry in same level\n",
    "                    if r[indent_attr] == cur_indent:\n",
    "                        # add in what the thing is not\n",
    "                        d3 = r['Description']\n",
    "                        if type(d3) == str and len(d3) > 0:\n",
    "                            t = '!' + format_desc(d3)\n",
    "                            res_parts.append(t)\n",
    "\n",
    "                    elif r[indent_attr] == cur_indent - 1:\n",
    "                        fd = r['full_desc']\n",
    "                        res = ' && '.join(res_parts)\n",
    "                        res = format_desc(res)\n",
    "                        res = fd + ' && ' + res\n",
    "                        res = format_desc(res)\n",
    "                        break\n",
    "\n",
    "                    cur_idx -= 1\n",
    "\n",
    "            else:\n",
    "                while cur_idx >= min_idx:\n",
    "                    r = df.loc[cur_idx]\n",
    "                    dsc = r['full_desc']\n",
    "                    if r[indent_attr] == cur_indent - 1:\n",
    "                        res = dsc + ' && ' + format_desc(cur_desc)\n",
    "                        break\n",
    "                    else:\n",
    "                        cur_idx -= 1\n",
    "        return res\n",
    "\n",
    "    def generate_desc(df):\n",
    "        df.at[:, 'full_desc'] = None\n",
    "        new_df = df.copy(deep=True)\n",
    "        for i, row in df.iterrows():\n",
    "            _desc = gen_aux_desc(new_df, i)\n",
    "            new_df.at[i, 'full_desc'] = _desc\n",
    "        return new_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df = pd.read_csv(file,index_col=0)\n",
    "    df = generate_desc(df)\n",
    "    try:\n",
    "        del df['Unnamed: 0']\n",
    "    except:\n",
    "        pass\n",
    "    print('main_3_aux', file)\n",
    "    print('-----------------')\n",
    "    df.to_csv(file)\n",
    "\n",
    "    \n",
    "def main_3():\n",
    "    files = get_file_list_2()\n",
    "    for inp in files :\n",
    "        main_3_aux(inp)\n",
    "        \n",
    "        \n",
    "main_3()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in keywords - unigrams, bi-grams and trigrams\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_in_kws hs_codes_file_1_1.csv\n",
      "-----------------\n",
      "add_in_kws hs_codes_file_2_1.csv\n",
      "-----------------\n",
      "add_in_kws hs_codes_file_3_1.csv\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "def add_in_kws(file):\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    df = gen_kw_2.add_in_kws(df)\n",
    "    df.to_csv(file)\n",
    "    print('add_in_kws', file)\n",
    "    print('-----------------')\n",
    "    return\n",
    "\n",
    "\n",
    "def main_4():\n",
    "    files = get_file_list_2()\n",
    "    for inp in files :\n",
    "        add_in_kws(inp)\n",
    "\n",
    "main_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-04a1e09ba2e9>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-04a1e09ba2e9>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    if EXPERIMENT = False :\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# def filter_by_hscodes(file):\n",
    "#     df = pd.read_csv(file,index_col=0)\n",
    "#     new_df = filter_hs_codes.filter_df(df ,level=2)\n",
    "#     new_df.to_csv(file)\n",
    "#     return\n",
    "\n",
    "\n",
    "# def main_6():\n",
    "#     global EXPERIMENT\n",
    "#     files = get_file_list_2()\n",
    "#     for inp in files :\n",
    "#         if EXPERIMENT == False :\n",
    "#             filter_by_hscodes(inp)\n",
    "# main_6()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Correct hs code format in hs_code_1_1\n",
    "def _insert_0(match):\n",
    "    txt = match.group(0)\n",
    "    txt = txt.split('.')\n",
    "    digit = txt[-1]\n",
    "    txt[-1] = '0'+ digit\n",
    "    z = '.'.join(txt)\n",
    "    return z\n",
    "\n",
    "def rectify_hs_code_format(row):\n",
    "    if type(row['hs_code']) == str:\n",
    "        pattern='\\.[0-9]$'\n",
    "        val = row['hs_code']\n",
    "        res = re.sub(pattern,_insert_0,val)\n",
    "        return res\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def main_6():\n",
    "    file = get_file_list_2()[0]\n",
    "    df = pd.read_csv(file,index_col=0)\n",
    "    try :\n",
    "        del df['Unnamed: 0.1']\n",
    "        del df['Unnamed: 0.1.1']\n",
    "    except :\n",
    "        pass\n",
    "    \n",
    "    df['hs_code'] = df.apply(rectify_hs_code_format,axis=1)\n",
    "    df.to_csv(file)\n",
    "\n",
    "    \n",
    "main_6()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
